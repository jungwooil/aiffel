{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exceptional-fever",
   "metadata": {},
   "source": [
    "## 텍스트 데이터의 특징\n",
    "- 텍스트를 어떻게 숫자 행렬로 표현할 수 있나요?\n",
    "- 텍스트에는 순서가 중요합니다. 입력 데이터의 순서를 인공지능 모델에 어떻게 반영해야 하나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-manual",
   "metadata": {},
   "source": [
    "### (1) 텍스트를 숫자로 표현하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-links",
   "metadata": {},
   "source": [
    "텍스트의 중요한 특징은 그 자체로는 기호일 뿐이며, 텍스트가 내포하는 의미를 기호가 직접 내포하지 않는다  \n",
    "(단어와 그 단어의 의미를 나타내는 벡터를 짝지어 본다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-taylor",
   "metadata": {},
   "source": [
    "3개의 짧은 문장으로 이루어진 텍스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifteen-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-slide",
   "metadata": {},
   "source": [
    "텍스트 데이터로부터 사전을 만들기 위해 모든 문장을 단어 단위로 쪼갠 후에 파이썬 딕셔너리`dict` 자료구조로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "after-controversy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-evanescence",
   "metadata": {},
   "source": [
    "텍스트를 숫자로 바꾸기 위해 딕셔너리를 {텍스트:인덱스} 구조로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metallic-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-reward",
   "metadata": {},
   "source": [
    "이 딕셔너리는 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opening-animal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-imperial",
   "metadata": {},
   "source": [
    "내가 가진 텍스트 데이터를 숫자로 바꿔 표현해보면,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "injured-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-challenge",
   "metadata": {},
   "source": [
    "`get_encoded_sentence` 함수를 통해 아래와 같이 맵핑된 것을 확인할 수 있다\n",
    "\n",
    "- \\<BOS> -> 1\n",
    "- i -> 3\n",
    "- eat -> 6\n",
    "- lunch -> 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "documented-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-coast",
   "metadata": {},
   "source": [
    "반대로, encode된 벡터를 decode하여 다시 원래 텍스트 데이터로 복구할 수도 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latin-beaver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reflected-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-fourth",
   "metadata": {},
   "source": [
    "### (2) Embedding 레이어의 등장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-rough",
   "metadata": {},
   "source": [
    "텍스트가 숫자로 변환되어 인공지능 모델의 입력으로 사용될 수 있게 되었지만, 이 벡터는 텍스트에 담긴 언어의 의미와 대응되는 벡터가 아니라 임의로 부여된 단어의 순서에 불과하다.  \n",
    "\n",
    "하지만, 우리는 단어와 그 단어의 의미를 나타내는 벡터를 짝짓고, 단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화하게 된다. 이러한 단어를 벡터로 표현하는 방법을 워드 임베딩(Word Embedding)이라고 한다.  \n",
    "\n",
    "Tensorflow, Pytorch 등의 딥러닝 프레임워크들은 이러한 의미벡터 파라미터를 구현한 Embedding 레이어를 제공한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "perceived-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8c0dfc25fa8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    959\u001b[0m         np_arrays.ndarray, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 960\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3307\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3308\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3309\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3310\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \"\"\"\n\u001b[1;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1405\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-lemon",
   "metadata": {},
   "source": [
    "Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 일정해야 한다  \n",
    "\n",
    "Tensorflow에서는 `keras.preprocessing.sequence.pad_sequences`라는 편리한 함수를 통해 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공한다  \n",
    "(문장 벡터의 길이가 일정하지 않으면 Error가 발생한다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "robust-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "southwest-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.00925422 -0.03588488 -0.00971211  0.02802808]\n",
      "  [-0.03891928 -0.0451986   0.01079522  0.03708781]\n",
      "  [-0.04781001  0.02706623 -0.04801406 -0.04713613]\n",
      "  [-0.01864877  0.03660406  0.02886262 -0.04537164]\n",
      "  [-0.01028968 -0.04863708  0.02795089 -0.02727573]]\n",
      "\n",
      " [[-0.00925422 -0.03588488 -0.00971211  0.02802808]\n",
      "  [-0.03891928 -0.0451986   0.01079522  0.03708781]\n",
      "  [-0.03791126 -0.00695167 -0.02399545 -0.00650684]\n",
      "  [-0.00615288  0.01166967 -0.03711499 -0.0065214 ]\n",
      "  [-0.01028968 -0.04863708  0.02795089 -0.02727573]]\n",
      "\n",
      " [[-0.00925422 -0.03588488 -0.00971211  0.02802808]\n",
      "  [-0.00274182  0.00145074  0.04794297  0.01662626]\n",
      "  [-0.03891928 -0.0451986   0.01079522  0.03708781]\n",
      "  [-0.04781001  0.02706623 -0.04801406 -0.04713613]\n",
      "  [ 0.02969391  0.01623916  0.03713747  0.01186759]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-architecture",
   "metadata": {},
   "source": [
    "## 시퀀스 데이터를 다루는 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-factory",
   "metadata": {},
   "source": [
    "텍스트 데이터를 다루는 데 주로 사용되는 딥러닝 모델은 `Recurrent Neural Network(RNN)`이다  \n",
    "RNN은 시퀀스(Sequence) 형태의 데이터를 처리하기에 최적인 모델이다  \n",
    "RNN은 시간의 흐름에 따라 새롭게 들어오는 입력에 따라 변하는 현재 상태를 묘사하는 state machine으로 설계되었다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-valuable",
   "metadata": {},
   "source": [
    "#### RNN 모델을 사용하여 텍스트 데이터 처리하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "passive-vitamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-concrete",
   "metadata": {},
   "source": [
    "RNN 이외의 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "occasional-trial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unable-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-research",
   "metadata": {},
   "source": [
    "## IMDb 영화리뷰 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-participant",
   "metadata": {},
   "source": [
    "### (1) IMDB 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "designed-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "related-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collected-moral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-poster",
   "metadata": {},
   "source": [
    "IMDb 데이터셋의 텍스트 인코딩을 위한 `word_to_index`, `index_to_word`는 아래와 같이 보정되어야 한다  \n",
    "`word_to_index`는 IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "flush-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-matthew",
   "metadata": {},
   "source": [
    "encode된 텍스트가 정상적으로 decode되는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "compressed-logic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-pollution",
   "metadata": {},
   "source": [
    "**pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일** (문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미친다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "separated-coral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-copying",
   "metadata": {},
   "source": [
    "padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "expensive-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-block",
   "metadata": {},
   "source": [
    "### (2) 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-veteran",
   "metadata": {},
   "source": [
    "#### RNN 모델의 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "olympic-smith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-program",
   "metadata": {},
   "source": [
    "#### model 훈련 전, 훈련용 데이터셋 25000건 중 10000건을 분리하여 검증셋(validation set)으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "municipal-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-reasoning",
   "metadata": {},
   "source": [
    "#### model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "missing-therapy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 7s 133ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5031\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.6929 - accuracy: 0.5183 - val_loss: 0.6929 - val_accuracy: 0.5013\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.6924 - accuracy: 0.5087 - val_loss: 0.6923 - val_accuracy: 0.5017\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.6895 - accuracy: 0.5173 - val_loss: 0.6911 - val_accuracy: 0.5039\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6823 - accuracy: 0.5263 - val_loss: 0.6890 - val_accuracy: 0.5094\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6760 - accuracy: 0.5338 - val_loss: 0.7028 - val_accuracy: 0.5057\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6717 - accuracy: 0.5380 - val_loss: 0.6940 - val_accuracy: 0.5100\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6719 - accuracy: 0.5405 - val_loss: 0.7011 - val_accuracy: 0.5090\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6699 - accuracy: 0.5355 - val_loss: 0.7037 - val_accuracy: 0.5102\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6686 - accuracy: 0.5413 - val_loss: 0.6997 - val_accuracy: 0.5076\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6706 - accuracy: 0.5321 - val_loss: 0.7053 - val_accuracy: 0.5092\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6731 - accuracy: 0.5477 - val_loss: 0.6911 - val_accuracy: 0.5069\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.6741 - accuracy: 0.5371 - val_loss: 0.7004 - val_accuracy: 0.5062\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6717 - accuracy: 0.5361 - val_loss: 0.7001 - val_accuracy: 0.5073\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.6710 - accuracy: 0.5348 - val_loss: 0.7065 - val_accuracy: 0.5069\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6688 - accuracy: 0.5362 - val_loss: 0.7093 - val_accuracy: 0.5063\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6705 - accuracy: 0.5361 - val_loss: 0.7115 - val_accuracy: 0.5064\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.6694 - accuracy: 0.5281 - val_loss: 0.7150 - val_accuracy: 0.5063\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.6676 - accuracy: 0.5402 - val_loss: 0.7167 - val_accuracy: 0.5064\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6679 - accuracy: 0.5393 - val_loss: 0.7188 - val_accuracy: 0.5070\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "residential-genesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 21s - loss: 0.7141 - accuracy: 0.5097\n",
      "[0.7140715718269348, 0.5097200274467468]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-organic",
   "metadata": {},
   "source": [
    "`model.fit()` 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장된다  \n",
    "이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지, 성능을 개선할 수 있는 다양한 아이디어를 얻을 수 있는 좋은 자료가 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rural-popularity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "competitive-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-receipt",
   "metadata": {},
   "source": [
    "Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정해 볼 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prospective-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-details",
   "metadata": {},
   "source": [
    "### (3) Word2Vec의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-tenant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-pavilion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install -U gensim==3.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-possibility",
   "metadata": {},
   "source": [
    "1. 데이터 준비와 확인 2. 데이터로더 구성 - 데이터의 중복 제거 - NaN 결측치 제거 - 한국어 토크나이저로 토큰화 - 불용어(Stopwords) 제거 - 사전word_to_index 구성 - 텍스트 스트링을 사전 인덱스 스트링으로 변환 - X_train, y_train, X_test, y_test, word_to_index 리턴 3. 모델구성을 위한 데이터 분석 및 가공 - 데이터셋 내 문장 길이 분포 - 적절한 최대 문장 길이 지정 - keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가 4. 모델구성 및 validation set 구성 5. 모델 훈련 개시 6. Loss, Accuracy 그래프 시각화 7. 학습된 Embedding 레이어 분석 8. 한국어 Word2Vec 임베딩 활용하여 성능개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-holmes",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
